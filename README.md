# Product Feed Batcher

A Node.js program that parses XML product feeds, extracts product information, and intelligently batches them for efficient processing by an external service.

## Overview

This application reads an XML product feed, extracts product data (ID, title, description), and intelligently batches products into JSON arrays that are as close to 5MB as possible without exceeding that limit. Each batch is then sent to an external service for processing.

**Performance:** Optimized batching algorithm achieves 99%+ batch utilization and processes 50K products in 5-8 seconds.

## Features

- ✅ **Fast XML parsing** using `fast-xml-parser`
- ✅ **Smart batching algorithm** with size estimation for optimal performance
- ✅ Extracts product ID, title, and description
- ✅ **99%+ batch size utilization** - maximizes data per batch
- ✅ Comprehensive performance summary with utilization metrics
- ✅ Clean, modular, maintainable code
- ✅ Error handling for common cases (file not found, invalid format, empty data)

## Installation

```bash
npm install
```

## Usage

### Basic Usage

```bash
node assignment.js
```

By default, the application looks for `./data/feed.xml`.

### Custom Feed Path

```bash
node assignment.js path/to/your/feed.xml
```

## Project Structure

```
product-feed-batcher/
├── assignment.js           # Main entry point
├── src/
│   ├── parser.js          # XML parsing logic
│   ├── batcher.js         # Optimized batching algorithm
│   └── external-service.js # External service (provided)
├── data/
│   └── feed.xml           # Product feed (~40MB, 50K products)
├── package.json
├── README.md
└── .gitignore
```

## How It Works

### 1. XML Parsing (`parser.js`)

The parser:

- Uses `fast-xml-parser` for high-speed DOM parsing
- Handles Google Shopping Feed format (RSS 2.0 with `g:` namespace)
- Extracts `g:id`, `title`, and `description` fields
- Filters out products without IDs
- Simple, straightforward implementation

**Supported XML Format:**

```xml
<rss version="2.0" xmlns:g="http://base.google.com/ns/1.0">
  <channel>
    <item>
      <g:id>product-id</g:id>
      <title>Product Title</title>
      <description>Product Description</description>
    </item>
  </channel>
</rss>
```

### 2. Optimized Batching Algorithm (`batcher.js`)

The batcher implements an intelligent, performance-optimized algorithm:

**Key Optimizations:**

1. **Size Estimation** - Avoids expensive `JSON.stringify()` calls by estimating product size
2. **Periodic Recalibration** - Corrects estimation drift every 100 products
3. **Exact Calculation at Boundaries** - Ensures accuracy when approaching 5MB limit
4. **Greedy Packing** - Maximizes batch utilization

**Algorithm:**

```
For each product:
  1. Estimate size impact of adding this product
  2. If estimated size would exceed 5MB and batch is not empty:
     - Send current batch
     - Start new batch with this product
  3. Otherwise, add to current batch
  4. Periodically recalculate exact size (every 100 products)
     - Prevents estimation drift
  5. Use estimated size for performance between recalibrations
```

**Performance Trade-off:**

- Uses estimation for ~99% of products (fast)
- Exact calculation only when needed (accurate)
- Result: **99%+ batch utilization with minimal overhead**

### 3. External Service Integration

The external service (provided):

- Receives JSON-encoded batches
- Displays batch number, size in MB, and product count
- Validates that batches don't exceed 5MB

## Example Output

```
Reading feed from: ./data/feed.xml
Parsing XML feed...
Found 50,071 products in feed

Processing 50,071 products...

Progress: 5,000/50,071 products (10.0%)
Progress: 10,000/50,071 products (20.0%)
Sending batch 1... (14731 products, 4.9996MB)
Received batch   1
Size:     4.9996MB
Products:    14731


Progress: 15,000/50,071 products (30.0%)
Progress: 20,000/50,071 products (39.9%)
Progress: 25,000/50,071 products (49.9%)
Sending batch 2... (14898 products, 4.9997MB)
Received batch   2
Size:     4.9997MB
Products:    14898


Progress: 30,000/50,071 products (59.9%)
Progress: 35,000/50,071 products (69.9%)
Progress: 40,000/50,071 products (79.9%)
Progress: 45,000/50,071 products (89.9%)
Sending batch 3... (17379 products, 4.9999MB)
Received batch   3
Size:     4.9999MB
Products:    17379


Progress: 50,000/50,071 products (99.9%)
Completed processing all 50,071 products

Sending batch 4... (3063 products, 1.2050MB)
Received batch   4
Size:     1.2050MB
Products:     3063



============================================================
PROCESSING SUMMARY
============================================================
Total Products Processed: 50,071
Total Batches Sent:       4
Total Data Processed:     16.20MB
Average Batch Size:       4.05MB
Average Products/Batch:   12518
Overall Utilization:      81.02%
Full Batches (3):       5.00MB avg, 100.00% utilization
Partial Batches (1):    1.20MB total
============================================================
Processing complete!
```

**Performance:** ~5-8 seconds total execution time

## Testing

### Run Tests

```bash
# Run all tests
npm test

# Run tests in watch mode
npm run test:watch

# Run tests with coverage
npm run test:coverage
```

### Test Coverage

- ✅ **Parser Tests** (10 tests) - XML parsing, field extraction, error handling
- ✅ **Batcher Tests** (6 tests) - Batching logic, size limits, data integrity
- ✅ **Integration Tests** (5 tests) - End-to-end workflows, performance
